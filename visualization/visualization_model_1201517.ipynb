{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Declare functions that import, normalize, and split data; train random forests model;\n",
    "return a dataframe of addresses, latitudes, longitudes, and probabilities of a fire.\n",
    "For now, functions require a single CSV of model inputs. \n",
    "In the future, we can transition to a SQL call to our database.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyglet\n",
    "import geoplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XY_data(input_file=None,multiclass=False):\n",
    "    #will process binary or multiclass\n",
    "\n",
    "    k=pd.read_csv(input_file,low_memory=False,)\n",
    "\n",
    "    # set target to Fire Incident Type\n",
    "    y=k.pop('Incident_Cat')\n",
    "    \n",
    "    # assign classes\n",
    "    # Nan becomes no incident\n",
    "    # Values either become an incident or classes of incidents\n",
    "    y=y.apply(lambda x:'0 No incident' if pd.isnull(x) else x if multiclass else '1 Incident')\n",
    "\n",
    "    #store class labels\n",
    "    unique=sorted(y.unique())\n",
    "\n",
    "    #substitue class index number for class description\n",
    "    y=y.apply(lambda x:unique.index(x))\n",
    "\n",
    "    # set x to remaining data\n",
    "    x=k\n",
    "    #calculate property age\n",
    "    x['age']=2016-x.Yr_Property_Built\n",
    "    #create one-hot variables for property type and neighborhood\n",
    "\n",
    "    return x,y,unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Data_normalized(input_file=None,multiclass=False):\n",
    "\n",
    "    x,y,unique=XY_data(input_file=input_file,multiclass=multiclass)\n",
    "\n",
    "    x_dummies=pd.get_dummies(data=x[['Building_Cat','Neighborhood']])\n",
    "\n",
    "    # get quantitative features\n",
    "\n",
    "    x_quantitative=x[['age','Num_Bathrooms', 'Num_Bedrooms',\n",
    "           'Num_Rooms', 'Num_Stories', 'Num_Units', 'Land_Value',\n",
    "           'Property_Area', 'Assessed_Improvement_Val', 'Tot_Rooms','Perc_Ownership' ,\n",
    "                      'count potential fire control', 'count all complaints',\n",
    "                      'count all complaints not corrected',\n",
    "                      'count potential fire control not corrected',\n",
    "                      'count fire emergency safety', 'count potential fire cause',\n",
    "                      'count fire emergency safety not corrected',\n",
    "                      'count potential fire cause not corrected'\n",
    "\n",
    "                      ]]\n",
    "\n",
    "    x_ids=x[['EAS','Address','Location_y']]\n",
    "    #normalize quantitative features\n",
    "    x_scaled=(x_quantitative-x_quantitative.mean())/(x_quantitative.max()-x_quantitative.min())\n",
    "\n",
    "\n",
    "    #combine x dummies and x scaled data\n",
    "    x_all=pd.concat([x_dummies,x_scaled],axis=1)\n",
    "\n",
    "    return x_all,y,unique,x_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(train=True,x=None,y=None,target_names=None,class_weight=None,multiclass=False,plot=False,cross_val=False):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    \n",
    "    # use multiclass random forest classifier for both binary and multiclass\n",
    "    if multiclass:\n",
    "\n",
    "        rf_model=OneVsRestClassifier(RandomForestClassifier(verbose=0,class_weight=class_weight),n_jobs=3)\n",
    "    else:\n",
    "        rf_model = RandomForestClassifier(verbose=0, class_weight=class_weight)\n",
    "            \n",
    "    print len(x),len(y)\n",
    "    \n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.33)\n",
    "\n",
    "    ## changing this to skip the if multiclass = true because I'm doing 0/1\n",
    "    ## and also ditch all the visualizations and also saving with file \n",
    "    ## because pickle is being weird on my machine :p\n",
    "    \n",
    "    train=train\n",
    "\n",
    "    if train: # run training and export to file\n",
    "        import csv\n",
    "        rf_model.fit(xtrain,ytrain)\n",
    "        predictions = rf_model.predict_proba(x)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_out(prediction_array=None,original_file=None):\n",
    "    k2=pd.read_csv(original_file,low_memory=False,)\n",
    "    predictions=pd.DataFrame(prediction_array)\n",
    "    output=pd.concat([k2,predictions],axis=1)\n",
    "    output.to_csv(path_or_buf='model_output_120517.csv',\n",
    "                  header=True,Index=False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(input_file=None):\n",
    "    if __name__ == '__main__':\n",
    "        multiclass = False\n",
    "        x,y,target_names,x_ids=Data_normalized(input_file=input_file,multiclass=multiclass)\n",
    "        predictions=classifier(train=True,x=x,y=y,target_names=target_names, class_weight=None,multiclass=multiclass,plot=False,cross_val=False)\n",
    "        output=predict_out(prediction_array=predictions,original_file=input_file)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Call data on most recent model inputs file (incl. census tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195308 195308\n"
     ]
    }
   ],
   "source": [
    "dataset=output(input_file='masterdf_inc_census_tract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -122.480327\n",
       "1   -122.418358\n",
       "2   -122.418358\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # visual check of lat field\n",
    "dataset.x[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # rename fields for mapping\n",
    "dataset=dataset.rename(columns={'x':'lon','y':'lat',0:'probability no fire',1:'probability fire'})\n",
    "mapslice=dataset[['lat','lon','probability fire']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## A first pass with Geoplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geoplotlib.utils import epoch_to_str, BoundingBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # set window and call data on mapslice; use I to zoom in, D to pan right, and W to pan up\n",
    "\n",
    "geoplotlib.set_bbox(BoundingBox(north=37.58,\n",
    "                               south=37.7,\n",
    "                               east=-122.281780,\n",
    "                               west= -123.02))\n",
    "geoplotlib.dot(mapslice)\n",
    "geoplotlib.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Map Requirements\n",
    "\n",
    "    1. A single dot per building -- no duplicates\n",
    "    2. Dot color based on probability of fire (0-1)\n",
    "    3. The ability to search a property: zoom in on a specific data point\n",
    "    4. Interactive labels when you hover over a dot\n",
    "    \n",
    "    Conclusion: geoplotlib is pretty and would probably allow us to build \n",
    "    these things custom in the nicest way, but it does not have enough built\n",
    "    in functionalities to get us to MVP ASAP. \n",
    "    \n",
    "    Stick with the Carto API!\n",
    "    \n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
